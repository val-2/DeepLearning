{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PikaPikaGen: Training del Modello\n",
                "\n",
                "Questo notebook automatizza il processo di setup e avvio del training per il modello PikaPikaGen.\n",
                "\n",
                "I passaggi eseguiti sono:\n",
                "1.  Clonazione del repository GitHub pubblico.\n",
                "2.  Installazione delle dipendenze necessarie tramite `uv`.\n",
                "3.  Esecuzione dello script di training `main.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Installazione delle dipendenze necessarie...\")\n",
                "\n",
                "# Assicurati che uv sia installato\n",
                "%pip install uv\n",
                "print(\"✅ uv installato con successo.\")\n",
                "\n",
                "# Controlla se torch è già installato\n",
                "try:\n",
                "    import torch\n",
                "    print(f\"✅ PyTorch già installato (versione: {torch.__version__})\")\n",
                "    torch_installed = True\n",
                "except ImportError:\n",
                "    print(\"❌ PyTorch non trovato, sarà installato\")\n",
                "    torch_installed = False\n",
                "\n",
                "# Lista delle dipendenze principali del progetto\n",
                "dependencies = [\n",
                "    \"transformers\",\n",
                "    \"pandas\",\n",
                "    \"tqdm\",\n",
                "    \"matplotlib\",\n",
                "    \"Pillow\",\n",
                "    \"requests\",\n",
                "    \"ipywidgets\"\n",
                "]\n",
                "\n",
                "# Aggiungi torch e torchvision solo se non sono già installati\n",
                "if not torch_installed:\n",
                "    dependencies.extend([\"torch\", \"torchvision\"])\n",
                "\n",
                "print(\"Installazione delle dipendenze con uv...\")\n",
                "deps_str = \" \".join(dependencies)\n",
                "if torch_installed:\n",
                "    !uv pip install {deps_str}\n",
                "else:\n",
                "    !uv pip install {deps_str} --torch-backend=auto\n",
                "print(\"✅ Dipendenze principali installate con successo.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "repo_url = \"https://github.com/val-2/DeepLearning\"\n",
                "branch = \"losses2\"\n",
                "repo_name = repo_url.split('/')[-1]\n",
                "\n",
                "print(f\"Clonazione del repository: {repo_url}\")\n",
                "\n",
                "# Check if we're already in the repo directory\n",
                "current_dir = os.path.basename(os.getcwd())\n",
                "if current_dir == repo_name:\n",
                "    print(f\"Già nella directory del repository '{repo_name}'. Aggiornamento...\")\n",
                "    !git fetch\n",
                "    !git pull\n",
                "    !git checkout {branch}\n",
                "elif os.path.exists(repo_name):\n",
                "    print(f\"La directory '{repo_name}' esiste già. Aggiornamento del repository...\")\n",
                "    os.chdir(repo_name)\n",
                "    !git fetch\n",
                "    !git pull\n",
                "    !git checkout {branch}\n",
                "else:\n",
                "    print(f\"Clonazione del repository...\")\n",
                "    !git clone -b {branch} {repo_url}\n",
                "    os.chdir(repo_name)\n",
                "\n",
                "# Spostati nella directory del repository\n",
                "print(f\"Directory di lavoro corrente: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Avvio dello script di training 'main.py'...\")\n",
                "%run pikapikagen/main.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import re\n",
                "\n",
                "def clean_checkpoints():\n",
                "    \"\"\"\n",
                "    Elimina tutti i checkpoint tranne il migliore (best_model.pth.tar), l'ultimo\n",
                "    e uno ogni 10 epoche\n",
                "    \"\"\"\n",
                "    checkpoint_dir = \"training_output/models\"\n",
                "\n",
                "    if not os.path.exists(checkpoint_dir):\n",
                "        print(f\"Directory {checkpoint_dir} non esiste.\")\n",
                "        return\n",
                "\n",
                "    # Trova tutti i checkpoint con pattern checkpoint_epoch_*.pth.tar\n",
                "    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pth.tar'))\n",
                "    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth.tar')\n",
                "\n",
                "    if not checkpoint_files:\n",
                "        print(\"Nessun checkpoint trovato.\")\n",
                "        return\n",
                "\n",
                "    # Trova l'ultimo checkpoint basandosi sul numero di epoca\n",
                "    try:\n",
                "        latest_checkpoint = max(checkpoint_files, key=lambda f: int(re.search(r'epoch_(\\d+)', f).group(1)))\n",
                "        print(f\"Ultimo checkpoint: {os.path.basename(latest_checkpoint)}\")\n",
                "    except (ValueError, AttributeError):\n",
                "        print(\"Impossibile determinare l'ultimo checkpoint.\")\n",
                "        return\n",
                "\n",
                "    # File da preservare\n",
                "    files_to_keep = {latest_checkpoint}\n",
                "    if os.path.exists(best_model_path):\n",
                "        files_to_keep.add(best_model_path)\n",
                "        print(f\"Best model trovato: {os.path.basename(best_model_path)}\")\n",
                "\n",
                "    # Aggiungi checkpoint ogni 10 epoche\n",
                "    for checkpoint_file in checkpoint_files:\n",
                "        match = re.search(r'epoch_(\\d+)', checkpoint_file)\n",
                "        if match:\n",
                "            epoch_num = int(match.group(1))\n",
                "            if epoch_num % 10 == 0:  # Ogni 10 epoche\n",
                "                files_to_keep.add(checkpoint_file)\n",
                "                print(f\"Conservato checkpoint ogni 10 epoche: {os.path.basename(checkpoint_file)}\")\n",
                "\n",
                "    # Elimina tutti gli altri checkpoint\n",
                "    deleted_count = 0\n",
                "    for checkpoint_file in checkpoint_files:\n",
                "        if checkpoint_file not in files_to_keep:\n",
                "            try:\n",
                "                os.remove(checkpoint_file)\n",
                "                print(f\"Eliminato: {os.path.basename(checkpoint_file)}\")\n",
                "                deleted_count += 1\n",
                "            except OSError as e:\n",
                "                print(f\"Errore nell'eliminazione di {checkpoint_file}: {e}\")\n",
                "\n",
                "    print(f\"\\n✅ Pulizia completata. Eliminati {deleted_count} checkpoint.\")\n",
                "    print(f\"File conservati:\")\n",
                "    for kept_file in files_to_keep:\n",
                "        if os.path.exists(kept_file):\n",
                "            print(f\"  - {os.path.basename(kept_file)}\")\n",
                "\n",
                "# Esegui la pulizia\n",
                "clean_checkpoints()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
